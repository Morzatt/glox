package scanner

import (
	"fmt"
)

type Scanner struct {
	// Source of the code to scan.
	Source string

	// List of tokens generated by the Scanner
	Tokens []Token

	// Points to the first character in the Lexeme being Scanned
	Start int

	// Points to at the character currently being scanned.
	Current int

	// line tracks what source line "current" is on, so it's possible to produce tokens that its
	// location is known.
	Line int
}

func (s *Scanner) ScanTokens() []Token {
	for !s.isAtEnd() {
		fmt.Printf("start: %d, current:%d \n", s.Start, s.Current)
		s.Start = s.Current
		s.scanToken()
	}
	s.Tokens = append(s.Tokens, Token{EOF, "", nil, s.Line})
	return s.Tokens
}

// Helper function that reports if all the characters were consumed.
func (s *Scanner) isAtEnd() bool {
	return s.Current >= len(s.Source)
}

// scanToken reads each individual character, then picks a token type for it.
func (s *Scanner) scanToken() {
	char := s.advance()
	switch char {
		case "(": s.addToken(LEFT_PAREN); 
		case ")": s.addToken(RIGHT_PAREN); 
		case "{": s.addToken(LEFT_BRACE); 
		case "}": s.addToken(RIGHT_BRACE); 
		case ",": s.addToken(COMMA); 
		case ".": s.addToken(DOT); 
		case "-": s.addToken(MINUS); 
		case "+": s.addToken(PLUS); 
		case ";": s.addToken(SEMICOLON); 
		case "*": s.addToken(STAR); 
	} 
}

// addToken grabs the text of the current lexeme and creates a new token for it.
func (s *Scanner) addToken(t TokenType, literal ...any) {
	text := string(s.Source[s.Start:s.Current])
	if literal != nil {
		s.Tokens = append(s.Tokens, Token{t, text, literal, s.Line})
	}
	s.Tokens = append(s.Tokens, Token{t, text, nil, s.Line})
}

// advance consumes the next character in the source file and returns it
func (s *Scanner) advance() string {
	s.Current++
	if (s.Current-1) == 0 {
		return string(s.Source[0])
	}
	return string(s.Source[s.Current-1])
}